{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/winequality-white.csv', ';')\n",
    "\n",
    "#define splits: \n",
    "#3-5: bad; 6: medium; 7-9: good\n",
    "bins = [3,5,6,9]\n",
    "quality_labels=[0,1,2]\n",
    "\n",
    "data['quality_labels'] = pd.cut(data['quality'], bins=bins, labels=quality_labels, include_lowest=True)\n",
    "features_raw = data.drop(['quality', 'quality_labels'], axis=1)\n",
    "labels_raw = data['quality_labels']\n",
    "\n",
    "#utility function to display results\n",
    "def print_res(search_obj):\n",
    "    res = pd.DataFrame.from_dict(search_obj.cv_results_).sort_values('rank_test_score')\n",
    "    cols = [c for c in res.columns if c[:5] != 'split' and c[-4:] != 'time']\n",
    "    display(res[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5347151403973234"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(activation='logistic', learning_rate_init=.0005)\n",
    "scores = cross_val_score(model, features_raw, labels_raw, cv=5, scoring=None)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=1,\n",
       "          param_distributions={'activation': ['tanh', 'logistic', 'relu', 'identity'], 'alpha': [0.0001, 0.001, 0.01, 0.1, 1], 'hidden_layer_sizes': [(5,), (10,), (20,), (50,), (100,), (200,)], 'learning_rate_init': [0.1, 0.5, 0.01, 0.005, 0.001, 0.0005, 0.0001]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "model = MLPClassifier()\n",
    "\n",
    "distr = {'activation': ['tanh', 'logistic', 'relu', 'identity'],\n",
    "         'alpha': [1e-4, 1e-3, 1e-2, .1, 1],\n",
    "         'hidden_layer_sizes': [(5,),(10,),(20,),(50,),(100,),(200,)],\n",
    "         'learning_rate_init': [.1,.5,.01,.005,.001,.0005,.0001]}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=distr, n_iter=100, cv=5, return_train_score=True)\n",
    "random_search.fit(features_raw, labels_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.535116</td>\n",
       "      <td>0.040196</td>\n",
       "      <td>1</td>\n",
       "      <td>0.557676</td>\n",
       "      <td>0.014917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.534096</td>\n",
       "      <td>0.050580</td>\n",
       "      <td>2</td>\n",
       "      <td>0.549051</td>\n",
       "      <td>0.011720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.534096</td>\n",
       "      <td>0.048170</td>\n",
       "      <td>2</td>\n",
       "      <td>0.528481</td>\n",
       "      <td>0.013078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.526337</td>\n",
       "      <td>0.043982</td>\n",
       "      <td>4</td>\n",
       "      <td>0.530779</td>\n",
       "      <td>0.012896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.523071</td>\n",
       "      <td>0.028686</td>\n",
       "      <td>5</td>\n",
       "      <td>0.546806</td>\n",
       "      <td>0.018428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.0001, 'hidden_layer_s...</td>\n",
       "      <td>0.517558</td>\n",
       "      <td>0.036487</td>\n",
       "      <td>6</td>\n",
       "      <td>0.544151</td>\n",
       "      <td>0.007283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.517558</td>\n",
       "      <td>0.058905</td>\n",
       "      <td>6</td>\n",
       "      <td>0.546601</td>\n",
       "      <td>0.004793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.025092</td>\n",
       "      <td>8</td>\n",
       "      <td>0.554870</td>\n",
       "      <td>0.015248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.512658</td>\n",
       "      <td>0.049466</td>\n",
       "      <td>9</td>\n",
       "      <td>0.534964</td>\n",
       "      <td>0.009001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.512250</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>10</td>\n",
       "      <td>0.521640</td>\n",
       "      <td>0.021714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.512250</td>\n",
       "      <td>0.045925</td>\n",
       "      <td>10</td>\n",
       "      <td>0.536903</td>\n",
       "      <td>0.010180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.510004</td>\n",
       "      <td>0.036210</td>\n",
       "      <td>12</td>\n",
       "      <td>0.541650</td>\n",
       "      <td>0.011985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.508779</td>\n",
       "      <td>0.048860</td>\n",
       "      <td>13</td>\n",
       "      <td>0.533281</td>\n",
       "      <td>0.021914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.507758</td>\n",
       "      <td>0.023074</td>\n",
       "      <td>14</td>\n",
       "      <td>0.556402</td>\n",
       "      <td>0.010285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.0001, 'hidden_layer_s...</td>\n",
       "      <td>0.504696</td>\n",
       "      <td>0.033944</td>\n",
       "      <td>15</td>\n",
       "      <td>0.540221</td>\n",
       "      <td>0.008791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.502246</td>\n",
       "      <td>0.075831</td>\n",
       "      <td>16</td>\n",
       "      <td>0.491220</td>\n",
       "      <td>0.025069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.501633</td>\n",
       "      <td>0.016316</td>\n",
       "      <td>17</td>\n",
       "      <td>0.507554</td>\n",
       "      <td>0.029193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.501021</td>\n",
       "      <td>0.048461</td>\n",
       "      <td>18</td>\n",
       "      <td>0.522101</td>\n",
       "      <td>0.009915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.500204</td>\n",
       "      <td>0.053573</td>\n",
       "      <td>19</td>\n",
       "      <td>0.541905</td>\n",
       "      <td>0.010981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.497346</td>\n",
       "      <td>0.051117</td>\n",
       "      <td>20</td>\n",
       "      <td>0.528229</td>\n",
       "      <td>0.024345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.0001, 'hidden_layer_s...</td>\n",
       "      <td>0.495713</td>\n",
       "      <td>0.023894</td>\n",
       "      <td>21</td>\n",
       "      <td>0.510158</td>\n",
       "      <td>0.010530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.492650</td>\n",
       "      <td>0.019799</td>\n",
       "      <td>22</td>\n",
       "      <td>0.510004</td>\n",
       "      <td>0.012051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.492446</td>\n",
       "      <td>0.054264</td>\n",
       "      <td>23</td>\n",
       "      <td>0.508729</td>\n",
       "      <td>0.006890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.489792</td>\n",
       "      <td>0.042795</td>\n",
       "      <td>24</td>\n",
       "      <td>0.497961</td>\n",
       "      <td>0.027033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.485096</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>25</td>\n",
       "      <td>0.514752</td>\n",
       "      <td>0.021719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.482646</td>\n",
       "      <td>0.027736</td>\n",
       "      <td>26</td>\n",
       "      <td>0.496019</td>\n",
       "      <td>0.026486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.480400</td>\n",
       "      <td>0.032080</td>\n",
       "      <td>27</td>\n",
       "      <td>0.482186</td>\n",
       "      <td>0.018857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.479992</td>\n",
       "      <td>0.056946</td>\n",
       "      <td>28</td>\n",
       "      <td>0.497194</td>\n",
       "      <td>0.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.479379</td>\n",
       "      <td>0.052097</td>\n",
       "      <td>29</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.012971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.478767</td>\n",
       "      <td>0.033793</td>\n",
       "      <td>30</td>\n",
       "      <td>0.495102</td>\n",
       "      <td>0.018910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.448755</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>69</td>\n",
       "      <td>0.448755</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.448755</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>69</td>\n",
       "      <td>0.448755</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.448755</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>69</td>\n",
       "      <td>0.448755</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.448755</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>69</td>\n",
       "      <td>0.448755</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.447734</td>\n",
       "      <td>0.037776</td>\n",
       "      <td>75</td>\n",
       "      <td>0.449261</td>\n",
       "      <td>0.037354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.445284</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>76</td>\n",
       "      <td>0.458709</td>\n",
       "      <td>0.019880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.444875</td>\n",
       "      <td>0.034879</td>\n",
       "      <td>77</td>\n",
       "      <td>0.449981</td>\n",
       "      <td>0.038344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.444671</td>\n",
       "      <td>0.017378</td>\n",
       "      <td>78</td>\n",
       "      <td>0.462282</td>\n",
       "      <td>0.039597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.442425</td>\n",
       "      <td>0.022256</td>\n",
       "      <td>79</td>\n",
       "      <td>0.473663</td>\n",
       "      <td>0.011634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.441200</td>\n",
       "      <td>0.034927</td>\n",
       "      <td>80</td>\n",
       "      <td>0.433596</td>\n",
       "      <td>0.046929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.440996</td>\n",
       "      <td>0.037203</td>\n",
       "      <td>81</td>\n",
       "      <td>0.469834</td>\n",
       "      <td>0.009371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.438955</td>\n",
       "      <td>0.022309</td>\n",
       "      <td>82</td>\n",
       "      <td>0.472744</td>\n",
       "      <td>0.030580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.435688</td>\n",
       "      <td>0.056668</td>\n",
       "      <td>83</td>\n",
       "      <td>0.461367</td>\n",
       "      <td>0.076617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.0001, 'hidden_layer_s...</td>\n",
       "      <td>0.428134</td>\n",
       "      <td>0.029407</td>\n",
       "      <td>84</td>\n",
       "      <td>0.459881</td>\n",
       "      <td>0.034246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.426092</td>\n",
       "      <td>0.045511</td>\n",
       "      <td>85</td>\n",
       "      <td>0.426045</td>\n",
       "      <td>0.045633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.426092</td>\n",
       "      <td>0.045511</td>\n",
       "      <td>85</td>\n",
       "      <td>0.425943</td>\n",
       "      <td>0.045582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.425888</td>\n",
       "      <td>0.045609</td>\n",
       "      <td>87</td>\n",
       "      <td>0.425988</td>\n",
       "      <td>0.045562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.425888</td>\n",
       "      <td>0.045609</td>\n",
       "      <td>87</td>\n",
       "      <td>0.425988</td>\n",
       "      <td>0.045562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.425888</td>\n",
       "      <td>0.045609</td>\n",
       "      <td>87</td>\n",
       "      <td>0.425988</td>\n",
       "      <td>0.045562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.403430</td>\n",
       "      <td>0.055815</td>\n",
       "      <td>90</td>\n",
       "      <td>0.403233</td>\n",
       "      <td>0.055892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.055812</td>\n",
       "      <td>91</td>\n",
       "      <td>0.403176</td>\n",
       "      <td>0.055811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.055812</td>\n",
       "      <td>91</td>\n",
       "      <td>0.403278</td>\n",
       "      <td>0.055894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.402205</td>\n",
       "      <td>0.092963</td>\n",
       "      <td>93</td>\n",
       "      <td>0.402302</td>\n",
       "      <td>0.092933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.380359</td>\n",
       "      <td>0.055794</td>\n",
       "      <td>94</td>\n",
       "      <td>0.380409</td>\n",
       "      <td>0.055815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.0001, 'hidden_layer_s...</td>\n",
       "      <td>0.379543</td>\n",
       "      <td>0.043471</td>\n",
       "      <td>95</td>\n",
       "      <td>0.388931</td>\n",
       "      <td>0.037822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.379339</td>\n",
       "      <td>0.092701</td>\n",
       "      <td>96</td>\n",
       "      <td>0.379536</td>\n",
       "      <td>0.092721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.355860</td>\n",
       "      <td>0.113829</td>\n",
       "      <td>97</td>\n",
       "      <td>0.355811</td>\n",
       "      <td>0.113821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>identity</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.354635</td>\n",
       "      <td>0.078470</td>\n",
       "      <td>98</td>\n",
       "      <td>0.381637</td>\n",
       "      <td>0.055107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'learning_rate_init': 0.0001, 'hidden_layer_s...</td>\n",
       "      <td>0.333197</td>\n",
       "      <td>0.037567</td>\n",
       "      <td>99</td>\n",
       "      <td>0.365348</td>\n",
       "      <td>0.042864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.287464</td>\n",
       "      <td>0.057989</td>\n",
       "      <td>100</td>\n",
       "      <td>0.287465</td>\n",
       "      <td>0.058017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_learning_rate_init param_hidden_layer_sizes param_alpha  \\\n",
       "5                     0.005                   (100,)       0.001   \n",
       "89                   0.0005                   (100,)      0.0001   \n",
       "15                    0.005                   (200,)         0.1   \n",
       "86                    0.005                   (200,)        0.01   \n",
       "14                    0.005                    (20,)        0.01   \n",
       "75                   0.0001                   (100,)        0.01   \n",
       "66                    0.005                    (10,)      0.0001   \n",
       "65                   0.0005                    (50,)       0.001   \n",
       "45                    0.005                    (20,)         0.1   \n",
       "38                    0.005                    (50,)        0.01   \n",
       "24                   0.0005                    (20,)           1   \n",
       "61                    0.001                    (10,)       0.001   \n",
       "78                    0.005                   (100,)      0.0001   \n",
       "40                    0.001                    (50,)       0.001   \n",
       "67                   0.0001                   (100,)           1   \n",
       "0                       0.1                    (10,)        0.01   \n",
       "97                    0.005                    (10,)         0.1   \n",
       "48                     0.01                     (5,)         0.1   \n",
       "90                     0.01                    (20,)        0.01   \n",
       "39                    0.005                    (50,)      0.0001   \n",
       "50                   0.0001                   (200,)        0.01   \n",
       "19                   0.0005                    (50,)           1   \n",
       "30                     0.01                     (5,)           1   \n",
       "74                     0.01                   (200,)           1   \n",
       "31                     0.01                    (50,)        0.01   \n",
       "21                   0.0005                    (10,)           1   \n",
       "94                      0.5                    (10,)         0.1   \n",
       "82                      0.1                    (50,)        0.01   \n",
       "77                    0.001                    (50,)      0.0001   \n",
       "32                    0.001                    (50,)       0.001   \n",
       "..                      ...                      ...         ...   \n",
       "57                      0.5                     (5,)           1   \n",
       "27                      0.5                    (50,)         0.1   \n",
       "6                       0.5                    (50,)       0.001   \n",
       "22                      0.1                    (20,)      0.0001   \n",
       "25                     0.01                    (50,)      0.0001   \n",
       "64                      0.1                     (5,)           1   \n",
       "96                    0.005                    (50,)      0.0001   \n",
       "93                     0.01                   (100,)       0.001   \n",
       "8                     0.001                    (50,)        0.01   \n",
       "51                     0.01                   (200,)        0.01   \n",
       "69                    0.001                    (20,)        0.01   \n",
       "26                   0.0005                    (50,)       0.001   \n",
       "28                      0.5                   (100,)      0.0001   \n",
       "76                   0.0001                    (10,)         0.1   \n",
       "1                       0.5                   (200,)      0.0001   \n",
       "10                      0.5                   (100,)         0.1   \n",
       "73                      0.5                    (20,)        0.01   \n",
       "4                       0.5                    (50,)      0.0001   \n",
       "2                       0.5                    (20,)       0.001   \n",
       "84                      0.1                   (100,)         0.1   \n",
       "55                      0.5                    (10,)           1   \n",
       "53                      0.5                   (100,)      0.0001   \n",
       "71                      0.5                   (100,)         0.1   \n",
       "54                      0.1                    (20,)        0.01   \n",
       "91                   0.0001                     (5,)         0.1   \n",
       "13                      0.5                   (200,)           1   \n",
       "56                      0.5                    (50,)        0.01   \n",
       "47                    0.005                   (200,)       0.001   \n",
       "29                   0.0001                     (5,)         0.1   \n",
       "80                      0.5                    (20,)      0.0001   \n",
       "\n",
       "   param_activation                                             params  \\\n",
       "5          logistic  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "89         logistic  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "15         logistic  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "86             tanh  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "14         logistic  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "75             tanh  {'learning_rate_init': 0.0001, 'hidden_layer_s...   \n",
       "66         logistic  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "65         logistic  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "45         logistic  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "38             relu  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "24             tanh  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "61         logistic  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "78         logistic  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "40             tanh  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "67             tanh  {'learning_rate_init': 0.0001, 'hidden_layer_s...   \n",
       "0          identity  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "97             tanh  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "48         logistic  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "90         logistic  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "39             tanh  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "50             relu  {'learning_rate_init': 0.0001, 'hidden_layer_s...   \n",
       "19             relu  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "30         logistic  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "74         logistic  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "31             tanh  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "21             relu  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "94         identity  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "82         identity  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "77         identity  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "32         identity  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "..              ...                                                ...   \n",
       "57             relu  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "27             relu  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "6              relu  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "22             relu  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "25         identity  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "64             relu  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "96         identity  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "93         identity  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "8          identity  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "51             relu  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "69         identity  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "26         identity  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "28         identity  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "76             relu  {'learning_rate_init': 0.0001, 'hidden_layer_s...   \n",
       "1          logistic  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "10             relu  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "73             tanh  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "4              relu  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "2              relu  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "84             tanh  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "55             relu  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "53         logistic  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "71         logistic  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "54         logistic  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "91         identity  {'learning_rate_init': 0.0001, 'hidden_layer_s...   \n",
       "13             tanh  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "56             tanh  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "47         identity  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "29             relu  {'learning_rate_init': 0.0001, 'hidden_layer_s...   \n",
       "80             tanh  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  mean_train_score  \\\n",
       "5          0.535116        0.040196                1          0.557676   \n",
       "89         0.534096        0.050580                2          0.549051   \n",
       "15         0.534096        0.048170                2          0.528481   \n",
       "86         0.526337        0.043982                4          0.530779   \n",
       "14         0.523071        0.028686                5          0.546806   \n",
       "75         0.517558        0.036487                6          0.544151   \n",
       "66         0.517558        0.058905                6          0.546601   \n",
       "65         0.516129        0.025092                8          0.554870   \n",
       "45         0.512658        0.049466                9          0.534964   \n",
       "38         0.512250        0.013870               10          0.521640   \n",
       "24         0.512250        0.045925               10          0.536903   \n",
       "61         0.510004        0.036210               12          0.541650   \n",
       "78         0.508779        0.048860               13          0.533281   \n",
       "40         0.507758        0.023074               14          0.556402   \n",
       "67         0.504696        0.033944               15          0.540221   \n",
       "0          0.502246        0.075831               16          0.491220   \n",
       "97         0.501633        0.016316               17          0.507554   \n",
       "48         0.501021        0.048461               18          0.522101   \n",
       "90         0.500204        0.053573               19          0.541905   \n",
       "39         0.497346        0.051117               20          0.528229   \n",
       "50         0.495713        0.023894               21          0.510158   \n",
       "19         0.492650        0.019799               22          0.510004   \n",
       "30         0.492446        0.054264               23          0.508729   \n",
       "74         0.489792        0.042795               24          0.497961   \n",
       "31         0.485096        0.047097               25          0.514752   \n",
       "21         0.482646        0.027736               26          0.496019   \n",
       "94         0.480400        0.032080               27          0.482186   \n",
       "82         0.479992        0.056946               28          0.497194   \n",
       "77         0.479379        0.052097               29          0.493976   \n",
       "32         0.478767        0.033793               30          0.495102   \n",
       "..              ...             ...              ...               ...   \n",
       "57         0.448755        0.000276               69          0.448755   \n",
       "27         0.448755        0.000276               69          0.448755   \n",
       "6          0.448755        0.000276               69          0.448755   \n",
       "22         0.448755        0.000276               69          0.448755   \n",
       "25         0.447734        0.037776               75          0.449261   \n",
       "64         0.445284        0.006832               76          0.458709   \n",
       "96         0.444875        0.034879               77          0.449981   \n",
       "93         0.444671        0.017378               78          0.462282   \n",
       "8          0.442425        0.022256               79          0.473663   \n",
       "51         0.441200        0.034927               80          0.433596   \n",
       "69         0.440996        0.037203               81          0.469834   \n",
       "26         0.438955        0.022309               82          0.472744   \n",
       "28         0.435688        0.056668               83          0.461367   \n",
       "76         0.428134        0.029407               84          0.459881   \n",
       "1          0.426092        0.045511               85          0.426045   \n",
       "10         0.426092        0.045511               85          0.425943   \n",
       "73         0.425888        0.045609               87          0.425988   \n",
       "4          0.425888        0.045609               87          0.425988   \n",
       "2          0.425888        0.045609               87          0.425988   \n",
       "84         0.403430        0.055815               90          0.403233   \n",
       "55         0.403226        0.055812               91          0.403176   \n",
       "53         0.403226        0.055812               91          0.403278   \n",
       "71         0.402205        0.092963               93          0.402302   \n",
       "54         0.380359        0.055794               94          0.380409   \n",
       "91         0.379543        0.043471               95          0.388931   \n",
       "13         0.379339        0.092701               96          0.379536   \n",
       "56         0.355860        0.113829               97          0.355811   \n",
       "47         0.354635        0.078470               98          0.381637   \n",
       "29         0.333197        0.037567               99          0.365348   \n",
       "80         0.287464        0.057989              100          0.287465   \n",
       "\n",
       "    std_train_score  \n",
       "5          0.014917  \n",
       "89         0.011720  \n",
       "15         0.013078  \n",
       "86         0.012896  \n",
       "14         0.018428  \n",
       "75         0.007283  \n",
       "66         0.004793  \n",
       "65         0.015248  \n",
       "45         0.009001  \n",
       "38         0.021714  \n",
       "24         0.010180  \n",
       "61         0.011985  \n",
       "78         0.021914  \n",
       "40         0.010285  \n",
       "67         0.008791  \n",
       "0          0.025069  \n",
       "97         0.029193  \n",
       "48         0.009915  \n",
       "90         0.010981  \n",
       "39         0.024345  \n",
       "50         0.010530  \n",
       "19         0.012051  \n",
       "30         0.006890  \n",
       "74         0.027033  \n",
       "31         0.021719  \n",
       "21         0.026486  \n",
       "94         0.018857  \n",
       "82         0.014109  \n",
       "77         0.012971  \n",
       "32         0.018910  \n",
       "..              ...  \n",
       "57         0.000069  \n",
       "27         0.000069  \n",
       "6          0.000069  \n",
       "22         0.000069  \n",
       "25         0.037354  \n",
       "64         0.019880  \n",
       "96         0.038344  \n",
       "93         0.039597  \n",
       "8          0.011634  \n",
       "51         0.046929  \n",
       "69         0.009371  \n",
       "26         0.030580  \n",
       "28         0.076617  \n",
       "76         0.034246  \n",
       "1          0.045633  \n",
       "10         0.045582  \n",
       "73         0.045562  \n",
       "4          0.045562  \n",
       "2          0.045562  \n",
       "84         0.055892  \n",
       "55         0.055811  \n",
       "53         0.055894  \n",
       "71         0.092933  \n",
       "54         0.055815  \n",
       "91         0.037822  \n",
       "13         0.092721  \n",
       "56         0.113821  \n",
       "47         0.055107  \n",
       "29         0.042864  \n",
       "80         0.058017  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_res(random_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=200, n_jobs=1,\n",
       "          param_distributions={'activation': ['tanh', 'logistic'], 'alpha': [0.0001, 0.001, 0.01, 0.1, 0.05, 0.005, 0.0005], 'hidden_layer_sizes': [(50,), (100,), (200,)], 'learning_rate_init': [0.1, 0.5, 0.01, 0.005, 0.001, 0.0005, 0.0001]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distr = {'activation': ['tanh', 'logistic'],\n",
    "         'alpha': [1e-4, 1e-3, 1e-2, .1, .05,.005,.0005],\n",
    "         'hidden_layer_sizes': [(50,),(100,),(200,)],\n",
    "         'learning_rate_init': [.1,.5,.01,.005,.001,.0005,.0001]}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=distr, n_iter=200, cv=5, return_train_score=True)\n",
    "random_search.fit(features_raw, labels_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.541445</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545019</td>\n",
       "      <td>0.007416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.539404</td>\n",
       "      <td>0.037376</td>\n",
       "      <td>2</td>\n",
       "      <td>0.545530</td>\n",
       "      <td>0.013965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.534300</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>3</td>\n",
       "      <td>0.556145</td>\n",
       "      <td>0.006807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.532666</td>\n",
       "      <td>0.027830</td>\n",
       "      <td>4</td>\n",
       "      <td>0.554001</td>\n",
       "      <td>0.011534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.531850</td>\n",
       "      <td>0.039208</td>\n",
       "      <td>5</td>\n",
       "      <td>0.536291</td>\n",
       "      <td>0.012550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.531441</td>\n",
       "      <td>0.040406</td>\n",
       "      <td>6</td>\n",
       "      <td>0.552573</td>\n",
       "      <td>0.009401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.530625</td>\n",
       "      <td>0.041972</td>\n",
       "      <td>7</td>\n",
       "      <td>0.551195</td>\n",
       "      <td>0.007415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.529808</td>\n",
       "      <td>0.033743</td>\n",
       "      <td>8</td>\n",
       "      <td>0.559412</td>\n",
       "      <td>0.007394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.527766</td>\n",
       "      <td>0.043012</td>\n",
       "      <td>9</td>\n",
       "      <td>0.545937</td>\n",
       "      <td>0.009119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.527358</td>\n",
       "      <td>0.036596</td>\n",
       "      <td>10</td>\n",
       "      <td>0.554718</td>\n",
       "      <td>0.019168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.525725</td>\n",
       "      <td>0.036291</td>\n",
       "      <td>11</td>\n",
       "      <td>0.543232</td>\n",
       "      <td>0.015942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.525521</td>\n",
       "      <td>0.046376</td>\n",
       "      <td>12</td>\n",
       "      <td>0.530729</td>\n",
       "      <td>0.018721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.049932</td>\n",
       "      <td>13</td>\n",
       "      <td>0.543639</td>\n",
       "      <td>0.008799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.522866</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>14</td>\n",
       "      <td>0.556911</td>\n",
       "      <td>0.019126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.522458</td>\n",
       "      <td>0.018311</td>\n",
       "      <td>15</td>\n",
       "      <td>0.521284</td>\n",
       "      <td>0.004528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.521437</td>\n",
       "      <td>0.026748</td>\n",
       "      <td>16</td>\n",
       "      <td>0.549254</td>\n",
       "      <td>0.013440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.521233</td>\n",
       "      <td>0.024790</td>\n",
       "      <td>17</td>\n",
       "      <td>0.545479</td>\n",
       "      <td>0.011837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.519600</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>18</td>\n",
       "      <td>0.544099</td>\n",
       "      <td>0.014554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.519600</td>\n",
       "      <td>0.031776</td>\n",
       "      <td>18</td>\n",
       "      <td>0.547060</td>\n",
       "      <td>0.009484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.0001, 'hidden_layer_s...</td>\n",
       "      <td>0.519396</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>20</td>\n",
       "      <td>0.538741</td>\n",
       "      <td>0.007331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.036809</td>\n",
       "      <td>21</td>\n",
       "      <td>0.538844</td>\n",
       "      <td>0.011770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.517967</td>\n",
       "      <td>0.041585</td>\n",
       "      <td>22</td>\n",
       "      <td>0.548131</td>\n",
       "      <td>0.012633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.517967</td>\n",
       "      <td>0.025637</td>\n",
       "      <td>22</td>\n",
       "      <td>0.558086</td>\n",
       "      <td>0.017738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.0001, 'hidden_layer_s...</td>\n",
       "      <td>0.516333</td>\n",
       "      <td>0.039301</td>\n",
       "      <td>24</td>\n",
       "      <td>0.539558</td>\n",
       "      <td>0.011366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.515108</td>\n",
       "      <td>0.035090</td>\n",
       "      <td>25</td>\n",
       "      <td>0.543845</td>\n",
       "      <td>0.009476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.001, 'hidden_layer_si...</td>\n",
       "      <td>0.514904</td>\n",
       "      <td>0.029179</td>\n",
       "      <td>26</td>\n",
       "      <td>0.548439</td>\n",
       "      <td>0.011745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.514700</td>\n",
       "      <td>0.032002</td>\n",
       "      <td>27</td>\n",
       "      <td>0.559718</td>\n",
       "      <td>0.009466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.0001, 'hidden_layer_s...</td>\n",
       "      <td>0.514292</td>\n",
       "      <td>0.033164</td>\n",
       "      <td>28</td>\n",
       "      <td>0.545224</td>\n",
       "      <td>0.018025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.0001, 'hidden_layer_s...</td>\n",
       "      <td>0.514087</td>\n",
       "      <td>0.034850</td>\n",
       "      <td>29</td>\n",
       "      <td>0.537209</td>\n",
       "      <td>0.007076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.0005, 'hidden_layer_s...</td>\n",
       "      <td>0.513883</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>30</td>\n",
       "      <td>0.546551</td>\n",
       "      <td>0.017085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.477746</td>\n",
       "      <td>0.037963</td>\n",
       "      <td>71</td>\n",
       "      <td>0.496991</td>\n",
       "      <td>0.032601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.01, 'hidden_layer_siz...</td>\n",
       "      <td>0.469988</td>\n",
       "      <td>0.022192</td>\n",
       "      <td>72</td>\n",
       "      <td>0.500459</td>\n",
       "      <td>0.013972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.005</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.005, 'hidden_layer_si...</td>\n",
       "      <td>0.456105</td>\n",
       "      <td>0.051420</td>\n",
       "      <td>73</td>\n",
       "      <td>0.514193</td>\n",
       "      <td>0.028806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.449163</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>74</td>\n",
       "      <td>0.448908</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.426092</td>\n",
       "      <td>0.045511</td>\n",
       "      <td>75</td>\n",
       "      <td>0.426045</td>\n",
       "      <td>0.045633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.426092</td>\n",
       "      <td>0.045511</td>\n",
       "      <td>75</td>\n",
       "      <td>0.425943</td>\n",
       "      <td>0.045582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.425888</td>\n",
       "      <td>0.045609</td>\n",
       "      <td>77</td>\n",
       "      <td>0.425988</td>\n",
       "      <td>0.045562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.425684</td>\n",
       "      <td>0.045313</td>\n",
       "      <td>78</td>\n",
       "      <td>0.426096</td>\n",
       "      <td>0.045659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.403634</td>\n",
       "      <td>0.055317</td>\n",
       "      <td>79</td>\n",
       "      <td>0.403125</td>\n",
       "      <td>0.055873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.403430</td>\n",
       "      <td>0.056150</td>\n",
       "      <td>80</td>\n",
       "      <td>0.403272</td>\n",
       "      <td>0.055854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.403430</td>\n",
       "      <td>0.055979</td>\n",
       "      <td>80</td>\n",
       "      <td>0.403227</td>\n",
       "      <td>0.055853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.055812</td>\n",
       "      <td>82</td>\n",
       "      <td>0.403176</td>\n",
       "      <td>0.055811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.403022</td>\n",
       "      <td>0.055809</td>\n",
       "      <td>83</td>\n",
       "      <td>0.403221</td>\n",
       "      <td>0.055813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.403022</td>\n",
       "      <td>0.055809</td>\n",
       "      <td>83</td>\n",
       "      <td>0.403119</td>\n",
       "      <td>0.055938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.403022</td>\n",
       "      <td>0.055809</td>\n",
       "      <td>83</td>\n",
       "      <td>0.403221</td>\n",
       "      <td>0.055813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.402205</td>\n",
       "      <td>0.092963</td>\n",
       "      <td>86</td>\n",
       "      <td>0.402302</td>\n",
       "      <td>0.092933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.402205</td>\n",
       "      <td>0.092963</td>\n",
       "      <td>86</td>\n",
       "      <td>0.402302</td>\n",
       "      <td>0.092933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.080109</td>\n",
       "      <td>88</td>\n",
       "      <td>0.402671</td>\n",
       "      <td>0.056692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.381380</td>\n",
       "      <td>0.089469</td>\n",
       "      <td>89</td>\n",
       "      <td>0.380160</td>\n",
       "      <td>0.091810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.380972</td>\n",
       "      <td>0.090251</td>\n",
       "      <td>90</td>\n",
       "      <td>0.382553</td>\n",
       "      <td>0.087624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.380359</td>\n",
       "      <td>0.055794</td>\n",
       "      <td>91</td>\n",
       "      <td>0.380409</td>\n",
       "      <td>0.055815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.092836</td>\n",
       "      <td>92</td>\n",
       "      <td>0.379650</td>\n",
       "      <td>0.092834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.379543</td>\n",
       "      <td>0.054655</td>\n",
       "      <td>93</td>\n",
       "      <td>0.380823</td>\n",
       "      <td>0.056359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.356676</td>\n",
       "      <td>0.086709</td>\n",
       "      <td>94</td>\n",
       "      <td>0.356724</td>\n",
       "      <td>0.086700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.356676</td>\n",
       "      <td>0.086632</td>\n",
       "      <td>94</td>\n",
       "      <td>0.357036</td>\n",
       "      <td>0.086219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.333810</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>96</td>\n",
       "      <td>0.333957</td>\n",
       "      <td>0.073500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.332993</td>\n",
       "      <td>0.103933</td>\n",
       "      <td>97</td>\n",
       "      <td>0.333038</td>\n",
       "      <td>0.103906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.311147</td>\n",
       "      <td>0.047282</td>\n",
       "      <td>98</td>\n",
       "      <td>0.311151</td>\n",
       "      <td>0.047385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>logistic</td>\n",
       "      <td>{'learning_rate_init': 0.5, 'hidden_layer_size...</td>\n",
       "      <td>0.310331</td>\n",
       "      <td>0.087253</td>\n",
       "      <td>99</td>\n",
       "      <td>0.310232</td>\n",
       "      <td>0.087164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.1</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'learning_rate_init': 0.1, 'hidden_layer_size...</td>\n",
       "      <td>0.310127</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>100</td>\n",
       "      <td>0.310373</td>\n",
       "      <td>0.087087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_learning_rate_init param_hidden_layer_sizes param_alpha  \\\n",
       "3                    0.0005                   (100,)        0.05   \n",
       "11                    0.001                    (50,)        0.01   \n",
       "47                    0.001                   (200,)       0.005   \n",
       "64                    0.001                   (200,)       0.001   \n",
       "41                     0.01                    (50,)        0.01   \n",
       "5                    0.0005                   (200,)      0.0005   \n",
       "77                    0.001                   (100,)      0.0005   \n",
       "76                    0.001                   (100,)       0.001   \n",
       "6                     0.001                   (100,)      0.0001   \n",
       "78                   0.0005                   (200,)        0.05   \n",
       "83                   0.0005                   (100,)      0.0001   \n",
       "42                     0.01                    (50,)         0.1   \n",
       "74                    0.005                   (200,)      0.0005   \n",
       "35                   0.0005                   (200,)      0.0005   \n",
       "91                     0.01                    (50,)       0.005   \n",
       "51                   0.0005                    (50,)         0.1   \n",
       "24                   0.0005                   (200,)         0.1   \n",
       "39                     0.01                    (50,)      0.0005   \n",
       "69                    0.001                   (100,)       0.005   \n",
       "8                    0.0001                   (200,)       0.005   \n",
       "70                    0.001                   (100,)         0.1   \n",
       "19                    0.001                    (50,)       0.005   \n",
       "87                   0.0005                   (100,)      0.0001   \n",
       "28                   0.0001                   (200,)       0.001   \n",
       "98                    0.005                    (50,)         0.1   \n",
       "4                     0.001                    (50,)      0.0001   \n",
       "73                   0.0005                   (100,)      0.0005   \n",
       "66                   0.0001                   (200,)         0.1   \n",
       "53                   0.0001                   (200,)      0.0005   \n",
       "63                   0.0005                    (50,)       0.005   \n",
       "..                      ...                      ...         ...   \n",
       "60                     0.01                   (200,)      0.0001   \n",
       "95                     0.01                   (200,)        0.01   \n",
       "22                    0.005                   (200,)       0.005   \n",
       "97                      0.1                   (100,)         0.1   \n",
       "65                      0.1                    (50,)      0.0001   \n",
       "68                      0.5                    (50,)       0.005   \n",
       "59                      0.1                   (200,)        0.01   \n",
       "33                      0.1                   (100,)        0.05   \n",
       "50                      0.1                    (50,)      0.0001   \n",
       "32                      0.1                    (50,)        0.05   \n",
       "79                      0.5                   (100,)      0.0005   \n",
       "92                      0.5                    (50,)       0.001   \n",
       "88                      0.5                   (100,)       0.005   \n",
       "48                      0.1                   (200,)       0.005   \n",
       "55                      0.5                    (50,)       0.001   \n",
       "99                      0.5                    (50,)         0.1   \n",
       "21                      0.1                   (100,)      0.0001   \n",
       "25                      0.5                   (200,)      0.0005   \n",
       "38                      0.1                   (100,)        0.05   \n",
       "67                      0.1                   (100,)      0.0005   \n",
       "57                      0.5                    (50,)      0.0001   \n",
       "9                       0.1                   (200,)       0.005   \n",
       "81                      0.1                   (100,)      0.0005   \n",
       "82                      0.5                   (200,)       0.005   \n",
       "7                       0.1                    (50,)         0.1   \n",
       "90                      0.1                   (100,)       0.005   \n",
       "12                      0.5                   (200,)      0.0005   \n",
       "56                      0.5                   (100,)       0.001   \n",
       "96                      0.5                    (50,)        0.01   \n",
       "89                      0.1                   (100,)       0.001   \n",
       "\n",
       "   param_activation                                             params  \\\n",
       "3          logistic  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "11         logistic  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "47         logistic  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "64         logistic  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "41             tanh  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "5          logistic  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "77             tanh  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "76             tanh  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "6          logistic  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "78             tanh  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "83         logistic  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "42         logistic  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "74         logistic  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "35             tanh  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "91         logistic  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "51             tanh  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "24         logistic  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "39         logistic  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "69             tanh  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "8          logistic  {'learning_rate_init': 0.0001, 'hidden_layer_s...   \n",
       "70         logistic  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "19         logistic  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "87             tanh  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "28         logistic  {'learning_rate_init': 0.0001, 'hidden_layer_s...   \n",
       "98             tanh  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "4              tanh  {'learning_rate_init': 0.001, 'hidden_layer_si...   \n",
       "73             tanh  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "66             tanh  {'learning_rate_init': 0.0001, 'hidden_layer_s...   \n",
       "53         logistic  {'learning_rate_init': 0.0001, 'hidden_layer_s...   \n",
       "63         logistic  {'learning_rate_init': 0.0005, 'hidden_layer_s...   \n",
       "..              ...                                                ...   \n",
       "60             tanh  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "95             tanh  {'learning_rate_init': 0.01, 'hidden_layer_siz...   \n",
       "22             tanh  {'learning_rate_init': 0.005, 'hidden_layer_si...   \n",
       "97             tanh  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "65         logistic  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "68             tanh  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "59             tanh  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "33             tanh  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "50             tanh  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "32         logistic  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "79         logistic  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "92         logistic  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "88         logistic  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "48             tanh  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "55             tanh  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "99             tanh  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "21             tanh  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "25             tanh  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "38         logistic  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "67             tanh  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "57             tanh  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "9          logistic  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "81         logistic  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "82         logistic  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "7              tanh  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "90             tanh  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "12         logistic  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "56             tanh  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "96         logistic  {'learning_rate_init': 0.5, 'hidden_layer_size...   \n",
       "89             tanh  {'learning_rate_init': 0.1, 'hidden_layer_size...   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  mean_train_score  \\\n",
       "3          0.541445        0.043868                1          0.545019   \n",
       "11         0.539404        0.037376                2          0.545530   \n",
       "47         0.534300        0.049322                3          0.556145   \n",
       "64         0.532666        0.027830                4          0.554001   \n",
       "41         0.531850        0.039208                5          0.536291   \n",
       "5          0.531441        0.040406                6          0.552573   \n",
       "77         0.530625        0.041972                7          0.551195   \n",
       "76         0.529808        0.033743                8          0.559412   \n",
       "6          0.527766        0.043012                9          0.545937   \n",
       "78         0.527358        0.036596               10          0.554718   \n",
       "83         0.525725        0.036291               11          0.543232   \n",
       "42         0.525521        0.046376               12          0.530729   \n",
       "74         0.524500        0.049932               13          0.543639   \n",
       "35         0.522866        0.034483               14          0.556911   \n",
       "91         0.522458        0.018311               15          0.521284   \n",
       "51         0.521437        0.026748               16          0.549254   \n",
       "24         0.521233        0.024790               17          0.545479   \n",
       "39         0.519600        0.032902               18          0.544099   \n",
       "69         0.519600        0.031776               18          0.547060   \n",
       "8          0.519396        0.039447               20          0.538741   \n",
       "70         0.518987        0.036809               21          0.538844   \n",
       "19         0.517967        0.041585               22          0.548131   \n",
       "87         0.517967        0.025637               22          0.558086   \n",
       "28         0.516333        0.039301               24          0.539558   \n",
       "98         0.515108        0.035090               25          0.543845   \n",
       "4          0.514904        0.029179               26          0.548439   \n",
       "73         0.514700        0.032002               27          0.559718   \n",
       "66         0.514292        0.033164               28          0.545224   \n",
       "53         0.514087        0.034850               29          0.537209   \n",
       "63         0.513883        0.028317               30          0.546551   \n",
       "..              ...             ...              ...               ...   \n",
       "60         0.477746        0.037963               71          0.496991   \n",
       "95         0.469988        0.022192               72          0.500459   \n",
       "22         0.456105        0.051420               73          0.514193   \n",
       "97         0.449163        0.000225               74          0.448908   \n",
       "65         0.426092        0.045511               75          0.426045   \n",
       "68         0.426092        0.045511               75          0.425943   \n",
       "59         0.425888        0.045609               77          0.425988   \n",
       "33         0.425684        0.045313               78          0.426096   \n",
       "50         0.403634        0.055317               79          0.403125   \n",
       "32         0.403430        0.056150               80          0.403272   \n",
       "79         0.403430        0.055979               80          0.403227   \n",
       "92         0.403226        0.055812               82          0.403176   \n",
       "88         0.403022        0.055809               83          0.403221   \n",
       "48         0.403022        0.055809               83          0.403119   \n",
       "55         0.403022        0.055809               83          0.403221   \n",
       "99         0.402205        0.092963               86          0.402302   \n",
       "21         0.402205        0.092963               86          0.402302   \n",
       "25         0.387097        0.080109               88          0.402671   \n",
       "38         0.381380        0.089469               89          0.380160   \n",
       "67         0.380972        0.090251               90          0.382553   \n",
       "57         0.380359        0.055794               91          0.380409   \n",
       "9          0.379747        0.092836               92          0.379650   \n",
       "81         0.379543        0.054655               93          0.380823   \n",
       "82         0.356676        0.086709               94          0.356724   \n",
       "7          0.356676        0.086632               94          0.357036   \n",
       "90         0.333810        0.073400               96          0.333957   \n",
       "12         0.332993        0.103933               97          0.333038   \n",
       "56         0.311147        0.047282               98          0.311151   \n",
       "96         0.310331        0.087253               99          0.310232   \n",
       "89         0.310127        0.087110              100          0.310373   \n",
       "\n",
       "    std_train_score  \n",
       "3          0.007416  \n",
       "11         0.013965  \n",
       "47         0.006807  \n",
       "64         0.011534  \n",
       "41         0.012550  \n",
       "5          0.009401  \n",
       "77         0.007415  \n",
       "76         0.007394  \n",
       "6          0.009119  \n",
       "78         0.019168  \n",
       "83         0.015942  \n",
       "42         0.018721  \n",
       "74         0.008799  \n",
       "35         0.019126  \n",
       "91         0.004528  \n",
       "51         0.013440  \n",
       "24         0.011837  \n",
       "39         0.014554  \n",
       "69         0.009484  \n",
       "8          0.007331  \n",
       "70         0.011770  \n",
       "19         0.012633  \n",
       "87         0.017738  \n",
       "28         0.011366  \n",
       "98         0.009476  \n",
       "4          0.011745  \n",
       "73         0.009466  \n",
       "66         0.018025  \n",
       "53         0.007076  \n",
       "63         0.017085  \n",
       "..              ...  \n",
       "60         0.032601  \n",
       "95         0.013972  \n",
       "22         0.028806  \n",
       "97         0.000269  \n",
       "65         0.045633  \n",
       "68         0.045582  \n",
       "59         0.045562  \n",
       "33         0.045659  \n",
       "50         0.055873  \n",
       "32         0.055854  \n",
       "79         0.055853  \n",
       "92         0.055811  \n",
       "88         0.055813  \n",
       "48         0.055938  \n",
       "55         0.055813  \n",
       "99         0.092933  \n",
       "21         0.092933  \n",
       "25         0.056692  \n",
       "38         0.091810  \n",
       "67         0.087624  \n",
       "57         0.055815  \n",
       "9          0.092834  \n",
       "81         0.056359  \n",
       "82         0.086700  \n",
       "7          0.086219  \n",
       "90         0.073500  \n",
       "12         0.103906  \n",
       "56         0.047385  \n",
       "96         0.087164  \n",
       "89         0.087087  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_res(random_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5712522148798233"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=1000)\n",
    "scores = cross_val_score(model, features_raw, labels_raw, cv=5, scoring=None)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44876050113610305"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "model = GaussianProcessClassifier()\n",
    "scores = cross_val_score(model, features_raw, labels_raw, cv=5, scoring=None)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5565597965437451"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "model = RidgeClassifier(normalize=False, fit_intercept=True, alpha=.0017)\n",
    "scores = cross_val_score(model, features_raw, labels_raw, cv=5, scoring=None)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "        tol=0.001),\n",
       "          fit_params=None, iid=True, n_iter=1000, n_jobs=1,\n",
       "          param_distributions={'alpha': array([0.001  , 0.001  , ..., 0.00998, 0.01   ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RidgeClassifier(normalize=False, fit_intercept=True)\n",
    "\n",
    "distr = {'alpha': np.logspace(-3,-2,1000)}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=distr, n_iter=1000, cv=5, return_train_score=True)\n",
    "random_search.fit(features_raw, labels_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.00166426</td>\n",
       "      <td>{'alpha': 0.0016642601764859037}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575694</td>\n",
       "      <td>0.008190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.00173476</td>\n",
       "      <td>{'alpha': 0.0017347593592339308}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.00173077</td>\n",
       "      <td>{'alpha': 0.0017307655341957258}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.00172678</td>\n",
       "      <td>{'alpha': 0.001726780903884356}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.00172281</td>\n",
       "      <td>{'alpha': 0.001722805447131394}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.00171884</td>\n",
       "      <td>{'alpha': 0.0017188391428171457}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.00171488</td>\n",
       "      <td>{'alpha': 0.001714881969870539}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.00171093</td>\n",
       "      <td>{'alpha': 0.0017109339072690151}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.00170699</td>\n",
       "      <td>{'alpha': 0.001706994934038408}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.00170307</td>\n",
       "      <td>{'alpha': 0.0017030650292528444}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.00169914</td>\n",
       "      <td>{'alpha': 0.001699144172034626}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.00169523</td>\n",
       "      <td>{'alpha': 0.0016952323415541197}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.00168744</td>\n",
       "      <td>{'alpha': 0.0016874356777273757}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.00169133</td>\n",
       "      <td>{'alpha': 0.0016913295170296488}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.00167967</td>\n",
       "      <td>{'alpha': 0.0016796748720926532}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.00167581</td>\n",
       "      <td>{'alpha': 0.0016758078645307671}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.00167195</td>\n",
       "      <td>{'alpha': 0.00167194975973199}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575694</td>\n",
       "      <td>0.008190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.0016681</td>\n",
       "      <td>{'alpha': 0.0016681005372000592}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575694</td>\n",
       "      <td>0.008190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.00166043</td>\n",
       "      <td>{'alpha': 0.0016604286571875295}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575796</td>\n",
       "      <td>0.008221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.00168355</td>\n",
       "      <td>{'alpha': 0.0016835508029612023}</td>\n",
       "      <td>0.556554</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.0017468</td>\n",
       "      <td>{'alpha': 0.0017467962151272458}</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.041661</td>\n",
       "      <td>21</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.00163009</td>\n",
       "      <td>{'alpha': 0.0016300923609797412}</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.041236</td>\n",
       "      <td>21</td>\n",
       "      <td>0.575898</td>\n",
       "      <td>0.008257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.00165661</td>\n",
       "      <td>{'alpha': 0.0016566059589499134}</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.041236</td>\n",
       "      <td>21</td>\n",
       "      <td>0.575796</td>\n",
       "      <td>0.008221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.00165279</td>\n",
       "      <td>{'alpha': 0.0016527920614648956}</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.041236</td>\n",
       "      <td>21</td>\n",
       "      <td>0.575898</td>\n",
       "      <td>0.008257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.00164899</td>\n",
       "      <td>{'alpha': 0.001648986944471065}</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.041236</td>\n",
       "      <td>21</td>\n",
       "      <td>0.575949</td>\n",
       "      <td>0.008261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.00164519</td>\n",
       "      <td>{'alpha': 0.0016451905877536625}</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.041236</td>\n",
       "      <td>21</td>\n",
       "      <td>0.575949</td>\n",
       "      <td>0.008261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.0016414</td>\n",
       "      <td>{'alpha': 0.0016414029711444664}</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.041236</td>\n",
       "      <td>21</td>\n",
       "      <td>0.575949</td>\n",
       "      <td>0.008261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.00173876</td>\n",
       "      <td>{'alpha': 0.0017387624002162504}</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.041661</td>\n",
       "      <td>21</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.00174277</td>\n",
       "      <td>{'alpha': 0.0017427746784089192}</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.041661</td>\n",
       "      <td>21</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.00175083</td>\n",
       "      <td>{'alpha': 0.001750827031735725}</td>\n",
       "      <td>0.556350</td>\n",
       "      <td>0.041661</td>\n",
       "      <td>21</td>\n",
       "      <td>0.575541</td>\n",
       "      <td>0.008154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>0.00619144</td>\n",
       "      <td>{'alpha': 0.006191441755977848}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041616</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574469</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>0.0062344</td>\n",
       "      <td>{'alpha': 0.006234401888627864}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041616</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574469</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>0.00622005</td>\n",
       "      <td>{'alpha': 0.006220048825634711}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041616</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574469</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>0.00807062</td>\n",
       "      <td>{'alpha': 0.008070620141149508}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0.00805204</td>\n",
       "      <td>{'alpha': 0.008052039670825477}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>0.0080335</td>\n",
       "      <td>{'alpha': 0.008033501977124734}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>0.00801501</td>\n",
       "      <td>{'alpha': 0.008015006961565405}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>0.00799655</td>\n",
       "      <td>{'alpha': 0.007996554525892346}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>0.00797814</td>\n",
       "      <td>{'alpha': 0.007978144572076629}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>0.00795978</td>\n",
       "      <td>{'alpha': 0.007959777002314986}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.00794145</td>\n",
       "      <td>{'alpha': 0.00794145171902934}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0.00792317</td>\n",
       "      <td>{'alpha': 0.007923168624866254}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0.00790493</td>\n",
       "      <td>{'alpha': 0.00790492762269642}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574367</td>\n",
       "      <td>0.005965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.00788673</td>\n",
       "      <td>{'alpha': 0.007886728615614156}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574367</td>\n",
       "      <td>0.005965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.00786857</td>\n",
       "      <td>{'alpha': 0.007868571506936851}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574367</td>\n",
       "      <td>0.005965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0.00785046</td>\n",
       "      <td>{'alpha': 0.00785045620020451}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0.00783238</td>\n",
       "      <td>{'alpha': 0.007832382599179196}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0.00781435</td>\n",
       "      <td>{'alpha': 0.007814350607844541}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0.00779636</td>\n",
       "      <td>{'alpha': 0.0077963601304052365}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.00777841</td>\n",
       "      <td>{'alpha': 0.00777841107128649}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0077605</td>\n",
       "      <td>{'alpha': 0.007760503335133571}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.00774264</td>\n",
       "      <td>{'alpha': 0.007742636826811269}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.00772481</td>\n",
       "      <td>{'alpha': 0.0077248114514034}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>0.00812662</td>\n",
       "      <td>{'alpha': 0.008126619200091946}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574265</td>\n",
       "      <td>0.006042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>0.00694771</td>\n",
       "      <td>{'alpha': 0.00694771254846024}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041616</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574418</td>\n",
       "      <td>0.006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.00626321</td>\n",
       "      <td>{'alpha': 0.006263207452198692}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041616</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574418</td>\n",
       "      <td>0.006033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>0.00624879</td>\n",
       "      <td>{'alpha': 0.006248788072006888}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041616</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574469</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>0.00810791</td>\n",
       "      <td>{'alpha': 0.008107909806731687}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.005943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>0.00620573</td>\n",
       "      <td>{'alpha': 0.0062057288067765}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041616</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574469</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0.00693172</td>\n",
       "      <td>{'alpha': 0.006931717276155407}</td>\n",
       "      <td>0.554512</td>\n",
       "      <td>0.041616</td>\n",
       "      <td>948</td>\n",
       "      <td>0.574418</td>\n",
       "      <td>0.006173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_alpha                            params  mean_test_score  \\\n",
       "221  0.00166426  {'alpha': 0.0016642601764859037}         0.556554   \n",
       "239  0.00173476  {'alpha': 0.0017347593592339308}         0.556554   \n",
       "238  0.00173077  {'alpha': 0.0017307655341957258}         0.556554   \n",
       "237  0.00172678   {'alpha': 0.001726780903884356}         0.556554   \n",
       "236  0.00172281   {'alpha': 0.001722805447131394}         0.556554   \n",
       "235  0.00171884  {'alpha': 0.0017188391428171457}         0.556554   \n",
       "234  0.00171488   {'alpha': 0.001714881969870539}         0.556554   \n",
       "233  0.00171093  {'alpha': 0.0017109339072690151}         0.556554   \n",
       "232  0.00170699   {'alpha': 0.001706994934038408}         0.556554   \n",
       "231  0.00170307  {'alpha': 0.0017030650292528444}         0.556554   \n",
       "230  0.00169914   {'alpha': 0.001699144172034626}         0.556554   \n",
       "229  0.00169523  {'alpha': 0.0016952323415541197}         0.556554   \n",
       "227  0.00168744  {'alpha': 0.0016874356777273757}         0.556554   \n",
       "228  0.00169133  {'alpha': 0.0016913295170296488}         0.556554   \n",
       "225  0.00167967  {'alpha': 0.0016796748720926532}         0.556554   \n",
       "224  0.00167581  {'alpha': 0.0016758078645307671}         0.556554   \n",
       "223  0.00167195    {'alpha': 0.00167194975973199}         0.556554   \n",
       "222   0.0016681  {'alpha': 0.0016681005372000592}         0.556554   \n",
       "220  0.00166043  {'alpha': 0.0016604286571875295}         0.556554   \n",
       "226  0.00168355  {'alpha': 0.0016835508029612023}         0.556554   \n",
       "242   0.0017468  {'alpha': 0.0017467962151272458}         0.556350   \n",
       "212  0.00163009  {'alpha': 0.0016300923609797412}         0.556350   \n",
       "219  0.00165661  {'alpha': 0.0016566059589499134}         0.556350   \n",
       "218  0.00165279  {'alpha': 0.0016527920614648956}         0.556350   \n",
       "217  0.00164899   {'alpha': 0.001648986944471065}         0.556350   \n",
       "216  0.00164519  {'alpha': 0.0016451905877536625}         0.556350   \n",
       "215   0.0016414  {'alpha': 0.0016414029711444664}         0.556350   \n",
       "240  0.00173876  {'alpha': 0.0017387624002162504}         0.556350   \n",
       "241  0.00174277  {'alpha': 0.0017427746784089192}         0.556350   \n",
       "243  0.00175083   {'alpha': 0.001750827031735725}         0.556350   \n",
       "..          ...                               ...              ...   \n",
       "791  0.00619144   {'alpha': 0.006191441755977848}         0.554512   \n",
       "794   0.0062344   {'alpha': 0.006234401888627864}         0.554512   \n",
       "793  0.00622005   {'alpha': 0.006220048825634711}         0.554512   \n",
       "906  0.00807062   {'alpha': 0.008070620141149508}         0.554512   \n",
       "905  0.00805204   {'alpha': 0.008052039670825477}         0.554512   \n",
       "904   0.0080335   {'alpha': 0.008033501977124734}         0.554512   \n",
       "903  0.00801501   {'alpha': 0.008015006961565405}         0.554512   \n",
       "902  0.00799655   {'alpha': 0.007996554525892346}         0.554512   \n",
       "901  0.00797814   {'alpha': 0.007978144572076629}         0.554512   \n",
       "900  0.00795978   {'alpha': 0.007959777002314986}         0.554512   \n",
       "899  0.00794145    {'alpha': 0.00794145171902934}         0.554512   \n",
       "898  0.00792317   {'alpha': 0.007923168624866254}         0.554512   \n",
       "897  0.00790493    {'alpha': 0.00790492762269642}         0.554512   \n",
       "896  0.00788673   {'alpha': 0.007886728615614156}         0.554512   \n",
       "895  0.00786857   {'alpha': 0.007868571506936851}         0.554512   \n",
       "894  0.00785046    {'alpha': 0.00785045620020451}         0.554512   \n",
       "893  0.00783238   {'alpha': 0.007832382599179196}         0.554512   \n",
       "892  0.00781435   {'alpha': 0.007814350607844541}         0.554512   \n",
       "891  0.00779636  {'alpha': 0.0077963601304052365}         0.554512   \n",
       "890  0.00777841    {'alpha': 0.00777841107128649}         0.554512   \n",
       "889   0.0077605   {'alpha': 0.007760503335133571}         0.554512   \n",
       "888  0.00774264   {'alpha': 0.007742636826811269}         0.554512   \n",
       "887  0.00772481     {'alpha': 0.0077248114514034}         0.554512   \n",
       "909  0.00812662   {'alpha': 0.008126619200091946}         0.554512   \n",
       "841  0.00694771    {'alpha': 0.00694771254846024}         0.554512   \n",
       "796  0.00626321   {'alpha': 0.006263207452198692}         0.554512   \n",
       "795  0.00624879   {'alpha': 0.006248788072006888}         0.554512   \n",
       "908  0.00810791   {'alpha': 0.008107909806731687}         0.554512   \n",
       "792  0.00620573     {'alpha': 0.0062057288067765}         0.554512   \n",
       "840  0.00693172   {'alpha': 0.006931717276155407}         0.554512   \n",
       "\n",
       "     std_test_score  rank_test_score  mean_train_score  std_train_score  \n",
       "221        0.041315                1          0.575694         0.008190  \n",
       "239        0.041315                1          0.575541         0.008154  \n",
       "238        0.041315                1          0.575541         0.008154  \n",
       "237        0.041315                1          0.575541         0.008154  \n",
       "236        0.041315                1          0.575541         0.008154  \n",
       "235        0.041315                1          0.575541         0.008154  \n",
       "234        0.041315                1          0.575541         0.008154  \n",
       "233        0.041315                1          0.575541         0.008154  \n",
       "232        0.041315                1          0.575541         0.008154  \n",
       "231        0.041315                1          0.575541         0.008154  \n",
       "230        0.041315                1          0.575541         0.008154  \n",
       "229        0.041315                1          0.575541         0.008154  \n",
       "227        0.041315                1          0.575541         0.008154  \n",
       "228        0.041315                1          0.575541         0.008154  \n",
       "225        0.041315                1          0.575541         0.008154  \n",
       "224        0.041315                1          0.575541         0.008154  \n",
       "223        0.041315                1          0.575694         0.008190  \n",
       "222        0.041315                1          0.575694         0.008190  \n",
       "220        0.041315                1          0.575796         0.008221  \n",
       "226        0.041315                1          0.575541         0.008154  \n",
       "242        0.041661               21          0.575541         0.008154  \n",
       "212        0.041236               21          0.575898         0.008257  \n",
       "219        0.041236               21          0.575796         0.008221  \n",
       "218        0.041236               21          0.575898         0.008257  \n",
       "217        0.041236               21          0.575949         0.008261  \n",
       "216        0.041236               21          0.575949         0.008261  \n",
       "215        0.041236               21          0.575949         0.008261  \n",
       "240        0.041661               21          0.575541         0.008154  \n",
       "241        0.041661               21          0.575541         0.008154  \n",
       "243        0.041661               21          0.575541         0.008154  \n",
       "..              ...              ...               ...              ...  \n",
       "791        0.041616              948          0.574469         0.006040  \n",
       "794        0.041616              948          0.574469         0.006040  \n",
       "793        0.041616              948          0.574469         0.006040  \n",
       "906        0.041945              948          0.574316         0.005943  \n",
       "905        0.041945              948          0.574316         0.005943  \n",
       "904        0.041945              948          0.574316         0.005943  \n",
       "903        0.041945              948          0.574316         0.005943  \n",
       "902        0.041945              948          0.574316         0.005943  \n",
       "901        0.041945              948          0.574316         0.005943  \n",
       "900        0.041945              948          0.574316         0.005943  \n",
       "899        0.041945              948          0.574316         0.005943  \n",
       "898        0.041945              948          0.574316         0.005943  \n",
       "897        0.041945              948          0.574367         0.005965  \n",
       "896        0.041945              948          0.574367         0.005965  \n",
       "895        0.041945              948          0.574367         0.005965  \n",
       "894        0.041945              948          0.574316         0.005962  \n",
       "893        0.041945              948          0.574316         0.005962  \n",
       "892        0.041945              948          0.574316         0.005962  \n",
       "891        0.041945              948          0.574316         0.005962  \n",
       "890        0.041945              948          0.574316         0.005962  \n",
       "889        0.041945              948          0.574316         0.005962  \n",
       "888        0.041945              948          0.574316         0.005962  \n",
       "887        0.041945              948          0.574316         0.005962  \n",
       "909        0.041945              948          0.574265         0.006042  \n",
       "841        0.041616              948          0.574418         0.006173  \n",
       "796        0.041616              948          0.574418         0.006033  \n",
       "795        0.041616              948          0.574469         0.006040  \n",
       "908        0.041945              948          0.574316         0.005943  \n",
       "792        0.041616              948          0.574469         0.006040  \n",
       "840        0.041616              948          0.574418         0.006173  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_res(random_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "\n",
    "distr = {'kernel': ['linear', 'rbf', 'poly', 'sigmoid', 'precomputed']}\n",
    "\n",
    "random_search = GridSearchCV(model, param_grid=distr, cv=5, return_train_score=True)\n",
    "random_search.fit(features_raw, labels_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')\n",
    "scores = cross_val_score(model, features_raw, labels_raw, cv=5, scoring=None)\n",
    "scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
